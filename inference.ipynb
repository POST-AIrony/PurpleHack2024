{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch clickhouse_connect scipy transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect, torch\n",
    "from scipy.spatial import distance\n",
    "from transformers import AutoModel, AutoTokenizer, Conversation, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(connection, table_name: str, vector: list[float], limit: int = 5):\n",
    "    res = []\n",
    "    with connection.query(f\"SELECT * FROM {table_name}\").rows_stream as stream:\n",
    "        for item in stream:\n",
    "            name, url, date, num, text, emb = item\n",
    "\n",
    "            dist = distance.cosine(vector, emb)\n",
    "            res.append(\n",
    "                {\n",
    "                    \"name\": name,\n",
    "                    \"url\": url,\n",
    "                    \"date\": date,\n",
    "                    \"num\": num,\n",
    "                    \"text\": text,\n",
    "                    \"dist\": dist,\n",
    "                }\n",
    "            )\n",
    "    res.sort(key=lambda x: x[\"dist\"])\n",
    "    return res[:limit]\n",
    "\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def txt2embeddings(text: str, tokenizer, model, device=\"cpu\"):\n",
    "    encoded_input = tokenizer(\n",
    "        [text],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    return mean_pooling(model_output, encoded_input[\"attention_mask\"])[0]\n",
    "\n",
    "\n",
    "def load_models(model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    model = AutoModel.from_pretrained(model)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def load_chatbot(model):\n",
    "    chatbot = pipeline(\n",
    "        model=model,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"cuda\",\n",
    "        task=\"conversational\",\n",
    "    )\n",
    "    return chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"716c-81-5-106-50.ngrok-free.app\"\n",
    "PORT = \"80\"\n",
    "TABLE_NAME = \"SbertEmb\"\n",
    "MODEL_EMB_NAME = \"ai-forever/sbert_large_nlu_ru\"\n",
    "MODEL_CHAT_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "system_prompt = \"\"\"\n",
    "INSTRUCT:\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don’t know the answer to a question, please don’t share false information.\n",
    "\n",
    "If you receive a question that is harmful, unethical, or inappropriate, end the dialogue immediately and do not provide a response. \n",
    "\n",
    "If you make a mistake, apologize and correct your answer.\n",
    "\n",
    "Generate a response based solely on the provided document.\n",
    "\n",
    "Answer the following question language based only on the CONTEXT provided.\n",
    "\n",
    "If you are unsure about your answer or the information in the document, suggest contacting support:\n",
    "Номер телефона: 8 800 300-30-00\n",
    "Почтовый адрес для письменных обращений: 107016, Москва, ул. Неглинная, д. 12, к. В, Банк России\n",
    "\n",
    "Отвечай только на русском языке.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = load_chatbot(MODEL_CHAT_NAME)\n",
    "tokenizer, model = load_models(MODEL_EMB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Как производится антимонопольная политика в России?\" #String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(conversation, max_new_tokens=512, pad_token_id=tokenizer.eos_token_id, temperature=0.7, top_k=100, top_p=0.95, repetition_penalty=2.0, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clickhouse_connect.get_client(\n",
    "    host=HOST, port=PORT\n",
    "    )\n",
    "print(\"Ping:\", client.ping())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_models(MODEL_EMB_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Purple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
